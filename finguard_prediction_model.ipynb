{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02918d0e-e968-46e6-9242-ab1e893b6da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296675, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2019-01-01 00:00:18  2703186189652095   \n",
       "1           1   2019-01-01 00:00:44      630423337322   \n",
       "2           2   2019-01-01 00:00:51    38859492057661   \n",
       "3           3   2019-01-01 00:01:16  3534093764340240   \n",
       "4           4   2019-01-01 00:03:06   375534208663984   \n",
       "\n",
       "                             merchant       category     amt      first  \\\n",
       "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
       "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
       "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
       "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
       "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
       "\n",
       "      last gender                        street  ...      lat      long  \\\n",
       "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
       "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
       "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
       "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
       "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job         dob  \\\n",
       "0      3495          Psychologist, counselling  1988-03-09   \n",
       "1       149  Special educational needs teacher  1978-06-21   \n",
       "2      4154        Nature conservation officer  1962-01-19   \n",
       "3      1939                    Patent attorney  1967-01-12   \n",
       "4        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"aml-dataset/fraudTrain.csv\")\n",
    "test_df = pd.read_csv(\"aml-dataset/fraudTest.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c08395d2-3452-45c1-acf3-e68f5775176f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt      first     last gender  \\\n",
       "0       misc_net    4.97   Jennifer    Banks      F   \n",
       "1    grocery_pos  107.23  Stephanie     Gill      F   \n",
       "2  entertainment  220.11     Edward  Sanchez      M   \n",
       "3  gas_transport   45.00     Jeremy    White      M   \n",
       "4       misc_pos   41.96      Tyler   Garcia      M   \n",
       "\n",
       "                         street            city  ...      lat      long  \\\n",
       "0                561 Perry Cove  Moravian Falls  ...  36.0788  -81.1781   \n",
       "1  43039 Riley Greens Suite 393          Orient  ...  48.8878 -118.2105   \n",
       "2      594 White Dale Suite 530      Malad City  ...  42.1808 -112.2620   \n",
       "3   9443 Cynthia Court Apt. 038         Boulder  ...  46.2306 -112.1138   \n",
       "4              408 Bradley Rest        Doe Hill  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job         dob  \\\n",
       "0      3495          Psychologist, counselling  1988-03-09   \n",
       "1       149  Special educational needs teacher  1978-06-21   \n",
       "2      4154        Nature conservation officer  1962-01-19   \n",
       "3      1939                    Patent attorney  1967-01-12   \n",
       "4        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if \"Unnamed: 0\" in train_df.columns:\n",
    "    train_df = train_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e20803b1-2bf4-4f98-97d0-91c1bf1e1a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b016366-ad9f-43c3-81dc-2b997fea1ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Using cached mysql_connector_python-9.4.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Using cached mysql_connector_python-9.4.0-py2.py3-none-any.whl (406 kB)\n",
      "Installing collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.4.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01052515-3cf1-4d01-ad09-8346a7102c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MySQL connector imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "print(\"✅ MySQL connector imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a08b01-260c-4dd3-8881-ce8b36b93050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aml_training_data',), ('fraud_training_data',)]\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"host\",         \n",
    "    user=\"sample_username\",              \n",
    "    password=\"sample_password\", \n",
    "    database=\"sample_database\",      \n",
    "    port=3306\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SHOW TABLES;\")\n",
    "print(cursor.fetchall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e60cd-0be6-48a7-8e0d-88b4988b031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create table dynamically (optional)\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS aml_training_data (\n",
    "    trans_date_trans_time VARCHAR(50),\n",
    "    cc_num BIGINT,\n",
    "    merchant VARCHAR(100),\n",
    "    category VARCHAR(50),\n",
    "    amt FLOAT,\n",
    "    first VARCHAR(50),\n",
    "    last VARCHAR(50),\n",
    "    gender VARCHAR(10),\n",
    "    street VARCHAR(100),\n",
    "    city VARCHAR(50),\n",
    "    state VARCHAR(10),\n",
    "    zip INT,\n",
    "    lat FLOAT,\n",
    "    `long` FLOAT,\n",
    "    city_pop INT,\n",
    "    job VARCHAR(100),\n",
    "    dob VARCHAR(50),\n",
    "    trans_num VARCHAR(50),\n",
    "    unix_time BIGINT,\n",
    "    merch_lat FLOAT,\n",
    "    merch_long FLOAT,\n",
    "    is_fraud INT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Insert data (simplified)\n",
    "for _, row in train_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO aml_training_data VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "    \"\"\", tuple(row))\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d936d64-8a42-4ae3-bb21-762bf1b50d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8d28898-6884-4c28-a647-65bc5c5061c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/6hmv9mws3x5_3b90dskdr6zw0000gn/T/ipykernel_3866/3334200883.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_model = pd.read_sql(\"SELECT * FROM aml_training_data\", conn)\n"
     ]
    }
   ],
   "source": [
    "df_model = pd.read_sql(\"SELECT * FROM aml_training_data\", conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e652bf51-c361-4e60-bca6-c8148563eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df_model['trans_date_trans_time'] = pd.to_datetime(df_model['trans_date_trans_time'])\n",
    "\n",
    "# Extract useful numeric features\n",
    "df_model['hour'] = df_model['trans_date_trans_time'].dt.hour\n",
    "df_model['day'] = df_model['trans_date_trans_time'].dt.day\n",
    "df_model['month'] = df_model['trans_date_trans_time'].dt.month\n",
    "df_model['weekday'] = df_model['trans_date_trans_time'].dt.weekday\n",
    "\n",
    "# Drop original timestamp\n",
    "df_model = df_model.drop(columns=['trans_date_trans_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0c964b6e-4a3f-465e-ae91-1c6f696d43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.drop(columns=[\"trans_num\", \"cc_num\"])  # cc_num is a unique ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "08f4ceb2-df2f-4f91-a34d-dc43d78c8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"merchant\", \"category\", \"first\", \"last\", \"gender\", \"street\", \n",
    "                    \"city\", \"state\", \"job\", \"dob\"]\n",
    "for col in categorical_cols:\n",
    "    if col in df_model.columns:\n",
    "        df_model[col] = LabelEncoder().fit_transform(df_model[col].astype(str))\n",
    "\n",
    "# Features / Target\n",
    "X = df_model.drop(columns=[\"is_fraud\"])\n",
    "y = df_model[\"is_fraud\"].astype(int)\n",
    "\n",
    "# Train/test split (stratified to keep frauds in both sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcaf009-cb86-44d4-b886-683ea1ae4ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Random Forest Classification -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.98      0.70      0.82      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.99      0.85      0.91    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "#  Random Forest (supervised)\n",
    "# --------------------------\n",
    "# Compute class weight for imbalance\n",
    "non_fraud = (y_train == 0).sum()\n",
    "fraud = (y_train == 1).sum()\n",
    "scale_pos_weight = non_fraud / fraud\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight={0:1, 1:int(scale_pos_weight)},  # heavily weight fraud class\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"----- Random Forest Classification -----\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4be9d-6ba4-4e87-a3c9-2d121cb4f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Isolation Forest Classification -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    257834\n",
      "           1       0.07      0.07      0.07      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.53      0.53      0.53    259335\n",
      "weighted avg       0.99      0.99      0.99    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Isolation Forest (unsupervised)\n",
    "# --------------------------\n",
    "iso_model = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=fraud / (fraud + non_fraud),  # approx fraction of fraud\n",
    "    random_state=42\n",
    ")\n",
    "iso_model.fit(X_train)  # fit on features only\n",
    "\n",
    "# Predict: -1 = anomaly (fraud), 1 = normal\n",
    "y_pred_iso = iso_model.predict(X_test)\n",
    "# Convert to 0/1\n",
    "y_pred_iso = [1 if x==-1 else 0 for x in y_pred_iso]\n",
    "\n",
    "print(\"----- Isolation Forest Classification -----\")\n",
    "print(classification_report(y_test, y_pred_iso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "45a1d0b0-e66b-4cb6-b7b8-3509970cb51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight={0:1, 1:10000},  # try lower than before\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d6a66829-26c1-4d9a-a46f-da0e87df5713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Random Forest Classification -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.98      0.71      0.82      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.99      0.86      0.91    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"----- Random Forest Classification -----\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e0f4f-8d16-43cb-a447-76d3b31072ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest PR-AUC: 0.9118843667505523\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# PR-AUC evaluation\n",
    "# --------------------------\n",
    "precision, recall, _ = precision_recall_curve(y_test, rf_model.predict_proba(X_test)[:,1])\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"Random Forest PR-AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "177b4ef0-4c3a-4fd6-b26d-8ecb23a70bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "test_df['trans_date_trans_time'] = pd.to_datetime(test_df['trans_date_trans_time'])\n",
    "\n",
    "# Extract useful numeric features\n",
    "test_df['hour'] = test_df['trans_date_trans_time'].dt.hour\n",
    "test_df['day'] = test_df['trans_date_trans_time'].dt.day\n",
    "test_df['month'] = test_df['trans_date_trans_time'].dt.month\n",
    "test_df['weekday'] = test_df['trans_date_trans_time'].dt.weekday\n",
    "\n",
    "# Drop original timestamp\n",
    "test_df = test_df.drop(columns=['trans_date_trans_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "296d5f6d-fc0b-41a1-a2a0-30c64f6f45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(columns=[\"Unnamed: 0\",\"trans_num\", \"cc_num\"])  # cc_num is a unique ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cdd78bad-3def-4f4f-8cfe-7ea6f5ef0737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.20      0.08      0.12      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.60      0.54      0.56    555719\n",
      "weighted avg       0.99      1.00      0.99    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\"merchant\", \"category\", \"first\", \"last\", \"gender\", \"street\", \n",
    "                    \"city\", \"state\", \"job\", \"dob\"]\n",
    "for col in categorical_cols:\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = LabelEncoder().fit_transform(test_df[col].astype(str))\n",
    "\n",
    "X_test = test_df.drop(columns=['is_fraud'])\n",
    "y_test = test_df['is_fraud']\n",
    "\n",
    "# y_pred = rf_model.predict(X_test)\n",
    "y_proba = rf_model.predict_proba(X_test)[:,1]\n",
    "threshold = 0.3  # lower from default 0.5\n",
    "y_pred = (y_proba > threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e8ee7229-98f3-4f0e-a57e-1347e1d964c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smote_tomek = SMOTETomek(sampling_strategy=0.1, random_state=42)\n",
    "X_res, y_res = smote_tomek.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6b6bd-7bfe-4b01-a48b-71e581bed56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After resampling, class distribution: [254923  22872]\n",
      "[0]\tvalidation_0-logloss:0.21870\n",
      "[1]\tvalidation_0-logloss:0.19373\n",
      "[2]\tvalidation_0-logloss:0.17605\n",
      "[3]\tvalidation_0-logloss:0.16269\n",
      "[4]\tvalidation_0-logloss:0.15297\n",
      "[5]\tvalidation_0-logloss:0.14499\n",
      "[6]\tvalidation_0-logloss:0.13726\n",
      "[7]\tvalidation_0-logloss:0.13046\n",
      "[8]\tvalidation_0-logloss:0.12475\n",
      "[9]\tvalidation_0-logloss:0.12275\n",
      "[10]\tvalidation_0-logloss:0.12158\n",
      "[11]\tvalidation_0-logloss:0.12020\n",
      "[12]\tvalidation_0-logloss:0.11921\n",
      "[13]\tvalidation_0-logloss:0.11470\n",
      "[14]\tvalidation_0-logloss:0.11045\n",
      "[15]\tvalidation_0-logloss:0.10741\n",
      "[16]\tvalidation_0-logloss:0.10446\n",
      "[17]\tvalidation_0-logloss:0.10206\n",
      "[18]\tvalidation_0-logloss:0.09993\n",
      "[19]\tvalidation_0-logloss:0.09901\n",
      "[20]\tvalidation_0-logloss:0.09696\n",
      "[21]\tvalidation_0-logloss:0.09473\n",
      "[22]\tvalidation_0-logloss:0.09296\n",
      "[23]\tvalidation_0-logloss:0.09104\n",
      "[24]\tvalidation_0-logloss:0.09028\n",
      "[25]\tvalidation_0-logloss:0.08952\n",
      "[26]\tvalidation_0-logloss:0.08770\n",
      "[27]\tvalidation_0-logloss:0.08641\n",
      "[28]\tvalidation_0-logloss:0.08533\n",
      "[29]\tvalidation_0-logloss:0.08452\n",
      "[30]\tvalidation_0-logloss:0.08389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [15:55:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\tvalidation_0-logloss:0.08335\n",
      "[32]\tvalidation_0-logloss:0.08264\n",
      "[33]\tvalidation_0-logloss:0.08151\n",
      "[34]\tvalidation_0-logloss:0.08092\n",
      "[35]\tvalidation_0-logloss:0.08036\n",
      "[36]\tvalidation_0-logloss:0.07971\n",
      "[37]\tvalidation_0-logloss:0.07914\n",
      "[38]\tvalidation_0-logloss:0.07846\n",
      "[39]\tvalidation_0-logloss:0.07783\n",
      "[40]\tvalidation_0-logloss:0.07745\n",
      "[41]\tvalidation_0-logloss:0.07655\n",
      "[42]\tvalidation_0-logloss:0.07611\n",
      "[43]\tvalidation_0-logloss:0.07515\n",
      "[44]\tvalidation_0-logloss:0.07471\n",
      "[45]\tvalidation_0-logloss:0.07400\n",
      "[46]\tvalidation_0-logloss:0.07333\n",
      "[47]\tvalidation_0-logloss:0.07276\n",
      "[48]\tvalidation_0-logloss:0.07232\n",
      "[49]\tvalidation_0-logloss:0.07187\n",
      "[50]\tvalidation_0-logloss:0.07150\n",
      "[51]\tvalidation_0-logloss:0.07112\n",
      "[52]\tvalidation_0-logloss:0.07076\n",
      "[53]\tvalidation_0-logloss:0.07018\n",
      "[54]\tvalidation_0-logloss:0.06964\n",
      "[55]\tvalidation_0-logloss:0.06908\n",
      "[56]\tvalidation_0-logloss:0.06856\n",
      "[57]\tvalidation_0-logloss:0.06823\n",
      "[58]\tvalidation_0-logloss:0.06798\n",
      "[59]\tvalidation_0-logloss:0.06754\n",
      "[60]\tvalidation_0-logloss:0.06705\n",
      "[61]\tvalidation_0-logloss:0.06674\n",
      "[62]\tvalidation_0-logloss:0.06626\n",
      "[63]\tvalidation_0-logloss:0.06578\n",
      "[64]\tvalidation_0-logloss:0.06525\n",
      "[65]\tvalidation_0-logloss:0.06500\n",
      "[66]\tvalidation_0-logloss:0.06439\n",
      "[67]\tvalidation_0-logloss:0.06405\n",
      "[68]\tvalidation_0-logloss:0.06375\n",
      "[69]\tvalidation_0-logloss:0.06339\n",
      "[70]\tvalidation_0-logloss:0.06309\n",
      "[71]\tvalidation_0-logloss:0.06282\n",
      "[72]\tvalidation_0-logloss:0.06249\n",
      "[73]\tvalidation_0-logloss:0.06222\n",
      "[74]\tvalidation_0-logloss:0.06185\n",
      "[75]\tvalidation_0-logloss:0.06158\n",
      "[76]\tvalidation_0-logloss:0.06121\n",
      "[77]\tvalidation_0-logloss:0.06098\n",
      "[78]\tvalidation_0-logloss:0.06076\n",
      "[79]\tvalidation_0-logloss:0.06038\n",
      "[80]\tvalidation_0-logloss:0.06015\n",
      "[81]\tvalidation_0-logloss:0.05999\n",
      "[82]\tvalidation_0-logloss:0.05969\n",
      "[83]\tvalidation_0-logloss:0.05932\n",
      "[84]\tvalidation_0-logloss:0.05901\n",
      "[85]\tvalidation_0-logloss:0.05885\n",
      "[86]\tvalidation_0-logloss:0.05852\n",
      "[87]\tvalidation_0-logloss:0.05822\n",
      "[88]\tvalidation_0-logloss:0.05806\n",
      "[89]\tvalidation_0-logloss:0.05774\n",
      "[90]\tvalidation_0-logloss:0.05750\n",
      "[91]\tvalidation_0-logloss:0.05733\n",
      "[92]\tvalidation_0-logloss:0.05708\n",
      "[93]\tvalidation_0-logloss:0.05682\n",
      "[94]\tvalidation_0-logloss:0.05652\n",
      "[95]\tvalidation_0-logloss:0.05617\n",
      "[96]\tvalidation_0-logloss:0.05593\n",
      "[97]\tvalidation_0-logloss:0.05567\n",
      "[98]\tvalidation_0-logloss:0.05520\n",
      "[99]\tvalidation_0-logloss:0.05499\n",
      "[100]\tvalidation_0-logloss:0.05483\n",
      "[101]\tvalidation_0-logloss:0.05435\n",
      "[102]\tvalidation_0-logloss:0.05422\n",
      "[103]\tvalidation_0-logloss:0.05394\n",
      "[104]\tvalidation_0-logloss:0.05366\n",
      "[105]\tvalidation_0-logloss:0.05334\n",
      "[106]\tvalidation_0-logloss:0.05312\n",
      "[107]\tvalidation_0-logloss:0.05296\n",
      "[108]\tvalidation_0-logloss:0.05276\n",
      "[109]\tvalidation_0-logloss:0.05253\n",
      "[110]\tvalidation_0-logloss:0.05217\n",
      "[111]\tvalidation_0-logloss:0.05187\n",
      "[112]\tvalidation_0-logloss:0.05174\n",
      "[113]\tvalidation_0-logloss:0.05154\n",
      "[114]\tvalidation_0-logloss:0.05135\n",
      "[115]\tvalidation_0-logloss:0.05121\n",
      "[116]\tvalidation_0-logloss:0.05108\n",
      "[117]\tvalidation_0-logloss:0.05097\n",
      "[118]\tvalidation_0-logloss:0.05079\n",
      "[119]\tvalidation_0-logloss:0.05048\n",
      "[120]\tvalidation_0-logloss:0.05022\n",
      "[121]\tvalidation_0-logloss:0.05000\n",
      "[122]\tvalidation_0-logloss:0.04967\n",
      "[123]\tvalidation_0-logloss:0.04946\n",
      "[124]\tvalidation_0-logloss:0.04930\n",
      "[125]\tvalidation_0-logloss:0.04904\n",
      "[126]\tvalidation_0-logloss:0.04882\n",
      "[127]\tvalidation_0-logloss:0.04859\n",
      "[128]\tvalidation_0-logloss:0.04839\n",
      "[129]\tvalidation_0-logloss:0.04829\n",
      "[130]\tvalidation_0-logloss:0.04811\n",
      "[131]\tvalidation_0-logloss:0.04788\n",
      "[132]\tvalidation_0-logloss:0.04771\n",
      "[133]\tvalidation_0-logloss:0.04747\n",
      "[134]\tvalidation_0-logloss:0.04705\n",
      "[135]\tvalidation_0-logloss:0.04694\n",
      "[136]\tvalidation_0-logloss:0.04678\n",
      "[137]\tvalidation_0-logloss:0.04672\n",
      "[138]\tvalidation_0-logloss:0.04660\n",
      "[139]\tvalidation_0-logloss:0.04642\n",
      "[140]\tvalidation_0-logloss:0.04618\n",
      "[141]\tvalidation_0-logloss:0.04609\n",
      "[142]\tvalidation_0-logloss:0.04585\n",
      "[143]\tvalidation_0-logloss:0.04573\n",
      "[144]\tvalidation_0-logloss:0.04555\n",
      "[145]\tvalidation_0-logloss:0.04526\n",
      "[146]\tvalidation_0-logloss:0.04510\n",
      "[147]\tvalidation_0-logloss:0.04481\n",
      "[148]\tvalidation_0-logloss:0.04454\n",
      "[149]\tvalidation_0-logloss:0.04441\n",
      "[150]\tvalidation_0-logloss:0.04427\n",
      "[151]\tvalidation_0-logloss:0.04411\n",
      "[152]\tvalidation_0-logloss:0.04386\n",
      "[153]\tvalidation_0-logloss:0.04373\n",
      "[154]\tvalidation_0-logloss:0.04361\n",
      "[155]\tvalidation_0-logloss:0.04335\n",
      "[156]\tvalidation_0-logloss:0.04322\n",
      "[157]\tvalidation_0-logloss:0.04311\n",
      "[158]\tvalidation_0-logloss:0.04293\n",
      "[159]\tvalidation_0-logloss:0.04277\n",
      "[160]\tvalidation_0-logloss:0.04266\n",
      "[161]\tvalidation_0-logloss:0.04258\n",
      "[162]\tvalidation_0-logloss:0.04251\n",
      "[163]\tvalidation_0-logloss:0.04229\n",
      "[164]\tvalidation_0-logloss:0.04214\n",
      "[165]\tvalidation_0-logloss:0.04202\n",
      "[166]\tvalidation_0-logloss:0.04177\n",
      "[167]\tvalidation_0-logloss:0.04129\n",
      "[168]\tvalidation_0-logloss:0.04103\n",
      "[169]\tvalidation_0-logloss:0.04085\n",
      "[170]\tvalidation_0-logloss:0.04053\n",
      "[171]\tvalidation_0-logloss:0.04042\n",
      "[172]\tvalidation_0-logloss:0.04026\n",
      "[173]\tvalidation_0-logloss:0.04017\n",
      "[174]\tvalidation_0-logloss:0.04009\n",
      "[175]\tvalidation_0-logloss:0.03996\n",
      "[176]\tvalidation_0-logloss:0.03981\n",
      "[177]\tvalidation_0-logloss:0.03969\n",
      "[178]\tvalidation_0-logloss:0.03958\n",
      "[179]\tvalidation_0-logloss:0.03944\n",
      "[180]\tvalidation_0-logloss:0.03921\n",
      "[181]\tvalidation_0-logloss:0.03908\n",
      "[182]\tvalidation_0-logloss:0.03896\n",
      "[183]\tvalidation_0-logloss:0.03879\n",
      "[184]\tvalidation_0-logloss:0.03866\n",
      "[185]\tvalidation_0-logloss:0.03856\n",
      "[186]\tvalidation_0-logloss:0.03847\n",
      "[187]\tvalidation_0-logloss:0.03829\n",
      "[188]\tvalidation_0-logloss:0.03812\n",
      "[189]\tvalidation_0-logloss:0.03788\n",
      "[190]\tvalidation_0-logloss:0.03766\n",
      "[191]\tvalidation_0-logloss:0.03749\n",
      "[192]\tvalidation_0-logloss:0.03731\n",
      "[193]\tvalidation_0-logloss:0.03716\n",
      "[194]\tvalidation_0-logloss:0.03696\n",
      "[195]\tvalidation_0-logloss:0.03686\n",
      "[196]\tvalidation_0-logloss:0.03677\n",
      "[197]\tvalidation_0-logloss:0.03667\n",
      "[198]\tvalidation_0-logloss:0.03656\n",
      "[199]\tvalidation_0-logloss:0.03619\n",
      "Best threshold based on F1: 0.6931061\n",
      "----- XGBoost Classification Report -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.75      0.69      0.72      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.87      0.84      0.86   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n",
      "PR-AUC: 0.7545630919313235\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cat_cols = ['merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "\n",
    "# Split features and target\n",
    "X = df_model.drop(columns=['is_fraud'])\n",
    "y = df_model['is_fraud']\n",
    "\n",
    "# -------------------------------\n",
    "#  Create a stratified sample for fast hyperparameter tuning\n",
    "# -------------------------------\n",
    "X_sample, _, y_sample, _ = train_test_split(\n",
    "    X, y, train_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "#  Handle imbalance using SMOTE + Tomek\n",
    "# -------------------------------\n",
    "smote_tomek = SMOTETomek(sampling_strategy=0.1, random_state=42)\n",
    "X_res, y_res = smote_tomek.fit_resample(X_sample, y_sample)\n",
    "\n",
    "print(\"After resampling, class distribution:\", np.bincount(y_res))\n",
    "\n",
    "# -------------------------------\n",
    "# Split train/validation for early stopping\n",
    "# -------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, stratify=y_res, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Train optimized XGBoost\n",
    "# -------------------------------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    tree_method='hist',  # use 'gpu_hist' if GPU available\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate on full dataset\n",
    "# -------------------------------\n",
    "y_pred_proba = xgb_model.predict_proba(X)[:,1]\n",
    "\n",
    "# Choose threshold based on PR curve\n",
    "precision, recall, thresholds = precision_recall_curve(y, y_pred_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Example: pick threshold maximizing F1-score\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "print(\"Best threshold based on F1:\", best_threshold)\n",
    "\n",
    "# Final predictions\n",
    "y_pred = (y_pred_proba > best_threshold).astype(int)\n",
    "\n",
    "# Classification report\n",
    "print(\"----- XGBoost Classification Report -----\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "print(\"PR-AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9d621-2e77-49a4-8f58-a66c7dee74a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold based on F1 (calibrated): 0.12611395120620728\n",
      "----- Calibrated XGBoost Classification Report -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00   1289169\n",
      "           1       0.45      0.83      0.58      7506\n",
      "\n",
      "    accuracy                           0.99   1296675\n",
      "   macro avg       0.72      0.91      0.79   1296675\n",
      "weighted avg       1.00      0.99      0.99   1296675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# # Wrap trained XGBoost model\n",
    "# calibrator = CalibratedClassifierCV(xgb_model, method='isotonic', cv='prefit')\n",
    "# calibrator.fit(X_val, y_val)  # use validation set\n",
    "\n",
    "# # Get calibrated probabilities\n",
    "# y_calib_proba = calibrator.predict_proba(X)[:,1]\n",
    "calibrator = CalibratedClassifierCV(xgb_model, method='sigmoid', cv='prefit')\n",
    "calibrator.fit(X_val, y_val)  # use validation set\n",
    "\n",
    "# -------------------------------\n",
    "# Get calibrated probabilities on the full dataset\n",
    "# -------------------------------\n",
    "y_calib_proba = calibrator.predict_proba(X)[:,1]\n",
    "\n",
    "# -------------------------------\n",
    "# Compute optimal threshold based on validation set\n",
    "# -------------------------------\n",
    "y_val_proba = calibrator.predict_proba(X_val)[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "\n",
    "# Compute F1 for each threshold\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "print(\"Best threshold based on F1 (calibrated):\", best_threshold)\n",
    "\n",
    "# -------------------------------\n",
    "# Make final predictions using calibrated probabilities and threshold\n",
    "# -------------------------------\n",
    "y_pred = (y_calib_proba > best_threshold).astype(int)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate model\n",
    "# -------------------------------\n",
    "print(\"----- Calibrated XGBoost Classification Report -----\")\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e64623de-a208-4f74-b080-69831defef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated model + threshold saved to xgb_calibrator.pkl\n"
     ]
    }
   ],
   "source": [
    "with open(\"xgb_calibrator.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"calibrator\": calibrator,\n",
    "        \"threshold\": best_threshold\n",
    "    }, f)\n",
    "\n",
    "print(\"Calibrated model + threshold saved to xgb_calibrator.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ec1233f2-79dd-43a9-af87-33f4de733946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = ['merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job']\n",
    "encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "    encoders[col] = le\n",
    "\n",
    "# Save encoders\n",
    "with open(\"encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoders, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
